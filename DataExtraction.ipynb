{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "import sklearn\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"32FINAL.csv\"\n",
    "DATAPATH = path.join(\"..\", \"capture\", \"processed\", DATASET)\n",
    "SAMPLES_TO_VIEW = [2,240,500,780]\n",
    "NORMALIZE_DATASET = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATAPATH)\n",
    "# dataset\n",
    "unique, counts = np.unique(dataset['Class'], return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize dataset to eliminate negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORMALIZE_DATASET:\n",
    "    # Drop class column and headers\n",
    "    dataset_array = dataset.iloc[:,:-1].to_numpy()\n",
    "    dataset_classes = np.expand_dims(dataset.iloc[:,-1].to_numpy(), axis=1)\n",
    "    dataset_columns = list(dataset.columns)\n",
    "\n",
    "    ds_min = dataset_array.min()\n",
    "    ds_max = dataset_array.max()\n",
    "    print(\"Current minimum: {}, Current maximum: {}\".format(ds_min, ds_max))\n",
    "\n",
    "    new_min = 0\n",
    "    new_max = ds_max + ((-1)*ds_min) # new max = max + min, \n",
    "    # i.e. it is a translation of scale from range -x to +y to range 0 to +y'\n",
    "    print(\"New minimum: {}, New maximum: {}\".format(new_min, new_max))\n",
    "\n",
    "    new_array = np.zeros((dataset_array.shape[0], dataset_array.shape[1]))\n",
    "\n",
    "    # Normalization\n",
    "    new_array = (((dataset_array - ds_min) / (ds_max - ds_min)) * new_max).astype(\"int64\")\n",
    "\n",
    "    new_array = np.concatenate((new_array, dataset_classes), axis=1)\n",
    "\n",
    "    # Convert to DataFrame again\n",
    "    dataset = pd.DataFrame(new_array, columns=dataset_columns, index=None)\n",
    "    # dataset\n",
    "    dataset.to_csv(path.join(\"..\",\"results\",\"extraction\",\"32FINAL_NORM.csv\"), sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [i for i in range(100)]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a figure with plots of the initial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(SAMPLES_TO_VIEW), 7, sharex='col', figsize=(21,len(SAMPLES_TO_VIEW)*3))\n",
    "for i in range(len(SAMPLES_TO_VIEW)):\n",
    "    for j in range(7):\n",
    "        y = dataset.iloc[i,j*100:(j+1)*100]\n",
    "        axs[i,j].plot(X, y)\n",
    "        if i == 0:\n",
    "            axs[i,j].set_title(dataset.columns[j*100][:-1], fontsize=15)\n",
    "\n",
    "fig.suptitle(\"Exemplo com \"+str(len(SAMPLES_TO_VIEW))+\" amostras\", fontsize=25)            \n",
    "# plt.show()\n",
    "fig.savefig(path.join(\"..\",\"results\",\"extraction\",\"plot\",DATASET[:-4]+\".PNG\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## Import extraction libraries\n",
    "Using code from Navar M. M. Nascimento -> https://github.com/navarmn/feature_extraction_signal for Fourier and HOS extraction.\n",
    "Using code from Geraldo LuÃ­s Bezerra Ramalho -> Private's Google Colaboratory for extraction using Structural Cooccurrence Matrix - SCM method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_extraction import Fourier, HOS\n",
    "from src.SCM import SCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_fourier25 = Fourier(fundamental=25.0, fs=100.0, harmonics=(1, 10, 20, 30))\n",
    "fe_fourier30 = Fourier(fundamental=30.0, fs=100.0, harmonics=(1, 10, 20, 30))\n",
    "fe_fourier35 = Fourier(fundamental=35.0, fs=100.0, harmonics=(1, 10, 20, 30))\n",
    "fe_HOS = HOS()\n",
    "fe_SCM = SCM(f=np.array([0]), g=np.array([0]), minmax=[0,0], NL=8, d=[0, 0], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is composed by 1100 sensor captures (dataset rows). Each one has 100 samples per measures (AcX, AcY, AcZ, GyX, GyY, GyZ, Tmp). The Tmp values will be despized for this work. So, we need to extract each measure's vector and generate a new dataset with features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding Tmp columns\n",
    "tmp_head = []\n",
    "for i in range(100):\n",
    "    tmp = \"Tmp\"+str(i)\n",
    "    tmp_head.append(tmp)\n",
    "if \"Tmp0\" in dataset.columns:\n",
    "    dataset = dataset.drop(columns=tmp_head)\n",
    "tmp_head.clear()\n",
    "# dataset\n",
    "\n",
    "import time\n",
    "\n",
    "current_milli_time = lambda: int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier extraction\n",
    "Fourier's extractor receive as parameters: fundamental frequency, sampling frequency and harmonics (multiples) of the input signal. Each class needs to be extracted for different configurations of the object, since classes differ themselves by fundamental frequency.\n",
    "\n",
    "Each measure (AcX, AcY, AcZ, GyX, GyY and GyZ) are extracted separated, since they are different signals, with 100 values. After extraction, will be 4 attributes for each measure, resulting in a dataset with 1100 rows and 25 columns ((4 attributes X 6 measures) + Class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_extraction(dataset, extractors, measures):\n",
    "    print('Fourier: ')\n",
    "    time_list = []\n",
    "    \n",
    "    out_data_list = []\n",
    "    out_row_list = []\n",
    "\n",
    "    for row in range(len(dataset.index)):\n",
    "        dataset_row = dataset.iloc[row,:]\n",
    "        class_num = dataset_row['Class']\n",
    "        dataset_fourier = dataset_row.values[:-1]\n",
    "        dataset_fourier = pd.DataFrame(np.reshape(dataset_fourier, (100,6), order='F'), columns=measures)\n",
    "        out_row_list.clear()\n",
    "        \n",
    "        extract_start = current_milli_time()\n",
    "        for measure in measures:\n",
    "            out_fourier = extractors[class_num].transform(dataset_fourier[measure])\n",
    "            out_row_list.append(out_fourier['features'])\n",
    "        extract_time = current_milli_time() - extract_start\n",
    "        time_list.append(extract_time)\n",
    "        \n",
    "        out_row_list.append([class_num])\n",
    "        row_list = [item for sublist in out_row_list for item in sublist]\n",
    "        out_data_list.append(row_list)\n",
    "\n",
    "    out_head = []\n",
    "    for measure in measures:\n",
    "        for i in range(4):\n",
    "            column = measure+str(i)\n",
    "            out_head.append(column)\n",
    "    out_head.append(\"Class\")\n",
    "\n",
    "    out_data_list = np.asarray(out_data_list)\n",
    "    out_dataframe = pd.DataFrame(out_data_list, columns=out_head, index=None)\n",
    "    out_dataframe = out_dataframe.astype({\"Class\": int})\n",
    "    \n",
    "    print(\"Amostras: \", len(time_list))\n",
    "    time_mean = np.mean(time_list)\n",
    "    print(\"Extraction time mean :\", time_mean)\n",
    "    time_std = np.std(time_list)\n",
    "    print(\"Extraction time std: \", time_std)\n",
    "    \n",
    "    return out_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOS extraction\n",
    "Higher-Order Statistics extractor do not receive parameters. All classes will be extracted in the same way. The resulting feature vector corresponds to four statistics of the input signal: rms, variance, skewness and the kurtosis.\n",
    "\n",
    "Each measure (AcX, AcY, AcZ, GyX, GyY and GyZ) are extracted separated, since they are different signals, with 100 values. After extraction, will be 4 attributes for each measure, resulting in a dataset with 1100 rows and 25 columns ((4 attributes X 6 measures) + Class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOS_extraction(dataset, extractor, measures):\n",
    "    print('HOS: ')\n",
    "    time_list = []    \n",
    "    \n",
    "    out_data_list = []\n",
    "    out_row_list = []\n",
    "\n",
    "    for row in range(len(dataset.index)):\n",
    "        dataset_row = dataset.iloc[row,:]\n",
    "        class_num = dataset_row['Class']\n",
    "        dataset_HOS = dataset_row.values[:-1]\n",
    "        dataset_HOS = pd.DataFrame(np.reshape(dataset_HOS, (100,6), order='F'), columns=measures)\n",
    "        out_row_list.clear()\n",
    "        \n",
    "        extract_start = current_milli_time()\n",
    "        for measure in measures:\n",
    "            out_HOS = extractor.transform(dataset_HOS[measure])\n",
    "            out_row_list.append(out_HOS['features'])\n",
    "        extract_time = current_milli_time() - extract_start\n",
    "        time_list.append(extract_time)\n",
    "        \n",
    "        out_row_list.append([class_num])\n",
    "        row_list = [item for sublist in out_row_list for item in sublist]\n",
    "        out_data_list.append(row_list)\n",
    "\n",
    "    out_head = []\n",
    "    for measure in measures:\n",
    "        for i in range(4):\n",
    "            column = measure+str(i)\n",
    "            out_head.append(column)\n",
    "    out_head.append(\"Class\")\n",
    "\n",
    "    out_data_list = np.asarray(out_data_list)\n",
    "    out_dataframe = pd.DataFrame(out_data_list, columns=out_head, index=None)\n",
    "    out_dataframe = out_dataframe.astype({\"Class\": int})\n",
    "    \n",
    "    print(\"Amostras: \", len(time_list))\n",
    "    time_mean = np.mean(time_list)\n",
    "    print(\"Extraction time mean :\", time_mean)\n",
    "    time_std = np.std(time_list)\n",
    "    print(\"Extraction time std: \", time_std)\n",
    "    \n",
    "    return out_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCM extraction\n",
    "Structural Cooccurrence Matrix is a analysis method that can be used as an extractor. All classes will be extracted in the same way. The resulting feature vector corresponds to eight features of the input signal, calculated from a matrix resulting of comparison between raw signal and the same signal, after a low-pass filter: COR, IDM, ENT, CSD, CSR, MDR, DKL and CAD.\n",
    "\n",
    "Each measure (AcX, AcY, AcZ, GyX, GyY and GyZ) are extracted separated, since they are different signals, with 100 values. After extraction, will be 8 attributes for each measure, resulting in a dataset with 1100 rows and 49 columns ((8 attributes X 6 measures) + Class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCM_extraction(dataset, extractor, signal_filter, measures):    \n",
    "    print('SCM: ')\n",
    "    time_list = []   \n",
    "    \n",
    "    out_data_list = []\n",
    "    out_row_list = []\n",
    "    \n",
    "    for row in range(len(dataset.index)):\n",
    "        dataset_row = dataset.iloc[row,:]\n",
    "        class_num = dataset_row['Class']\n",
    "        dataset_SCM = dataset_row.values[:-1]\n",
    "        dataset_SCM = pd.DataFrame(np.reshape(dataset_SCM, (100,6), order='F'), columns=measures)\n",
    "        out_row_list.clear()\n",
    "        \n",
    "        extract_start = current_milli_time()\n",
    "        for measure in measures:\n",
    "            signal_f = dataset_SCM[measure].to_numpy(dtype=\"int64\")\n",
    "            signal_g = dataset_SCM[measure].to_numpy(dtype=\"int64\")\n",
    "            signal_f = np.expand_dims(signal_f, axis=1)\n",
    "            signal_g = np.expand_dims(signal_g, axis=1)\n",
    "            signal_f = signal_f.T\n",
    "            signal_g = signal_g.T\n",
    "            extractor = SCM(f=signal_f, g=signal_g, minmax=[0,0], NL=8, d=[0, 0], verbose=False)\n",
    "            extractor.function_k = signal_filter\n",
    "            extractor.d = np.array([[0, 0]])\n",
    "            extractor.compute_matrix()\n",
    "            extractor.compute_attributes()\n",
    "            out_row_list.append(extractor.attributes.values())\n",
    "        extract_time = current_milli_time() - extract_start\n",
    "        time_list.append(extract_time)    \n",
    "        \n",
    "        out_row_list.append([class_num])\n",
    "        row_list = [item for sublist in out_row_list for item in sublist]\n",
    "        out_data_list.append(row_list)\n",
    "\n",
    "    out_head = []\n",
    "    for measure in measures:\n",
    "        for i in range(8):\n",
    "            column = measure+str(i)\n",
    "            out_head.append(column)\n",
    "    out_head.append(\"Class\")\n",
    "\n",
    "    out_data_list = np.asarray(out_data_list)\n",
    "    out_dataframe = pd.DataFrame(out_data_list, columns=out_head, index=None)\n",
    "    out_dataframe = out_dataframe.astype({\"Class\": int})\n",
    "    \n",
    "    print(\"Amostras: \", len(time_list))\n",
    "    time_mean = np.mean(time_list)\n",
    "    print(\"Extraction time mean :\", time_mean)\n",
    "    time_std = np.std(time_list)\n",
    "    print(\"Extraction time std: \", time_std)\n",
    "    \n",
    "    return out_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction general\n",
    "\n",
    "After call all functions and generate dataframes with corresponding features, CSV's of each dataframe would be saved in destiny folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "\n",
    "measures = [\"AcX\", \"AcY\", \"AcZ\", \"GyX\", \"GyY\", \"GyZ\"]\n",
    "fourier_extractors = [fe_fourier25, fe_fourier25, fe_fourier25, fe_fourier30, fe_fourier30, fe_fourier35] # class 0 to 5\n",
    "\n",
    "# user-defined k (low-pass average filter)\n",
    "def SCM_filter(s):\n",
    "  kernel = np.ones((3,3))\n",
    "  ret = scipy.ndimage.filters.convolve(s.astype(float), kernel, mode=\"reflect\")/kernel.sum()\n",
    "  return np.around(ret).astype(s.dtype)\n",
    "\n",
    "# Extraction functions\n",
    "fourier_dataframe = fourier_extraction(dataset, fourier_extractors, measures)\n",
    "HOS_dataframe = HOS_extraction(dataset, fe_HOS, measures)\n",
    "SCM_dataframe = SCM_extraction(dataset, fe_SCM, SCM_filter, measures)\n",
    "\n",
    "# Save CSV's\n",
    "fourier_dataframe.to_csv(path.join(\"..\",\"results\",\"extraction\", DATASET[:-4]+\"_Fourier.csv\"), sep=\",\", index=False)\n",
    "HOS_dataframe.to_csv(path.join(\"..\",\"results\",\"extraction\", DATASET[:-4]+\"_HOS.csv\"), sep=\",\", index=False)\n",
    "SCM_dataframe.to_csv(path.join(\"..\",\"results\",\"extraction\", DATASET[:-4]+\"_SCM.csv\"), sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features plotting\n",
    "\n",
    "Now, the features will be displayed, and the plot will be saved. That plot consists in a scatter matrix plot, which show a dispersion of elements, comparing pairs of features of a selected measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_cmap(N, base_cmap=None):\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)\n",
    "\n",
    "def plot_features(data_name, dataframe, classes, features, features_name, extractor_name):\n",
    "    plt.rcParams[\"figure.subplot.right\"] = .8\n",
    "\n",
    "    fig = pd.plotting.scatter_matrix(dataframe[[f for f in features]], figsize=(24,13), \n",
    "                                     c=dataframe[\"Class\"], label=classes, s=100, alpha=.8, \n",
    "                                     cmap=discrete_cmap(6, 'rainbow'))\n",
    "\n",
    "\n",
    "\n",
    "    handles = [plt.plot([], [], color=discrete_cmap(6, 'rainbow')(i), ls=\"\", marker=\".\", \n",
    "                        markersize=np.sqrt(50))[0] for i in range(6)]\n",
    "\n",
    "    plt.legend(handles, classes, loc=(1.02,0))\n",
    "    plt.suptitle(data_name + \" - \" + features_name + \" - \" + extractor_name, fontsize=24)\n",
    "    plt.savefig(path.join(\"..\",\"results\",\"extraction\",\"plot\",data_name+\"_\"+features_name+\"_\"+extractor_name+\".png\"), \n",
    "                dpi=300)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"25 NORMAL\", \"25 REVERSO\", \"25 VAZIO\", \"30 NORMAL\", \"30 VAZIO\", \"35 NORMAL\"]\n",
    "features_name = \"GyZ\"\n",
    "\n",
    "features = []\n",
    "for i in range(4):\n",
    "    feature = features_name+str(i)\n",
    "    features.append(feature)\n",
    "\n",
    "SCM_features = []\n",
    "for j in range(8):\n",
    "    feature = features_name+str(j)\n",
    "    SCM_features.append(feature)\n",
    "\n",
    "plot_features(DATASET[:-4], fourier_dataframe, labels, features, features_name, \"Fourier\")\n",
    "plot_features(DATASET[:-4], HOS_dataframe, labels, features, features_name, \"HOS\")\n",
    "plot_features(DATASET[:-4], SCM_dataframe, labels, SCM_features, features_name, \"SCM\")\n",
    "\n",
    "features.clear()\n",
    "SCM_features.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
