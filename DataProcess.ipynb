{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to set\n",
    "The result of MEASURE_MULTI x SAMPLES must be equal to number of rows of raw data (i.e. 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRCPATH = \"../capture\"\n",
    "OUTPATH = \"../capture/processed\"\n",
    "\n",
    "DATAFOLDERS = [\n",
    "    \"3225\",             # CLASS 0\n",
    "    \"3225_REVERSO\",     # CLASS 1\n",
    "    \"3225_VAZIO\",       # CLASS 2\n",
    "    \"3230\",             # CLASS 3\n",
    "    \"3230_VAZIO\",       # CLASS 4\n",
    "    \"3235\"              # CLASS 5\n",
    "]\n",
    "CLASSES = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "MEASURE_MULTI = 100\n",
    "SAMPLES = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw sensor data\n",
    "Each raw dataset has 2500 rows and 7 columns (AcX, AcY, AcZ, GyX, GyY, GyZ, Tmp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets from class 0: 10 with shape  (2500, 7)\n",
      "Datasets from class 1: 10 with shape  (2500, 7)\n",
      "Datasets from class 2: 3 with shape  (2500, 7)\n",
      "Datasets from class 3: 10 with shape  (2500, 7)\n",
      "Datasets from class 4: 1 with shape  (2500, 7)\n",
      "Datasets from class 5: 10 with shape  (2500, 7)\n"
     ]
    }
   ],
   "source": [
    "captures0 = []\n",
    "captures1 = []\n",
    "captures2 = []\n",
    "captures3 = []\n",
    "captures4 = []\n",
    "captures5 = []\n",
    "captures = [captures0, captures1, captures2, captures3, captures4, captures5]\n",
    "\n",
    "for i, DATAFOLDER in enumerate(DATAFOLDERS):\n",
    "    for _, _, DATAFILES in os.walk(SRCPATH+os.sep+DATAFOLDER):\n",
    "        for DATAFILE in DATAFILES:\n",
    "            df = pd.read_csv(SRCPATH+os.sep+DATAFOLDER+os.sep+DATAFILE)\n",
    "            captures[i].append(df)\n",
    "            \n",
    "for j, datasets in enumerate(captures):            \n",
    "    print(\"Datasets from class \"+str(j)+\": \"+str(len(datasets))+\" with shape \", datasets[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a new head for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    }
   ],
   "source": [
    "head = [\"AcX\", \"AcY\", \"AcZ\", \"GyX\", \"GyY\", \"GyZ\", \"Tmp\"]\n",
    "list_head = []\n",
    "\n",
    "for hd in head:        \n",
    "    for i in range(MEASURE_MULTI):\n",
    "        head_aux = hd + str(i)\n",
    "        list_head.append(head_aux)\n",
    "        \n",
    "print(len(list_head))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split each dataset into 25 samples and save them\n",
    "Each new dataset is composed by 25 samples with 100 values of each measure, i.e. 25 rows and 700 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Class, capture in enumerate(captures):\n",
    "    for idx,dataset in enumerate(capture):   \n",
    "        list_df = []\n",
    "        for i in range(SAMPLES):\n",
    "            lst = dataset.iloc[MEASURE_MULTI*i:MEASURE_MULTI*(i+1),:]\n",
    "            lst = lst.transpose()\n",
    "            lst = lst.values\n",
    "            lst = np.resize(lst, (1,7*MEASURE_MULTI))    \n",
    "            list_df.append(lst)\n",
    "        new_df = np.concatenate([i for i in list_df], axis=0)\n",
    "        new_df = pd.DataFrame(new_df, columns=list_head, index=None)\n",
    "        new_df.to_csv(OUTPATH+os.sep+DATAFOLDERS[Class]+os.sep+str(idx)+\"_\"+str(SAMPLES)+\"samples.csv\", \\\n",
    "                      sep=\",\", index=False)\n",
    "        list_df.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all saved datasets and concatenate them into one unique dataset\n",
    "Each dataset row has a class according to was describe above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_newdfs = []\n",
    "for i, DATAFOLDER in enumerate(DATAFOLDERS):\n",
    "    for _, _, DATAFILES in os.walk(OUTPATH+os.sep+DATAFOLDER):\n",
    "        for DATAFILE in DATAFILES:\n",
    "            newdf = pd.read_csv(OUTPATH+os.sep+DATAFOLDER+os.sep+DATAFILE)\n",
    "            class_col = [i] * 25\n",
    "            newdf[\"Class\"] = class_col\n",
    "            list_newdfs.append(newdf.values)\n",
    "final_df = np.concatenate([j for j in list_newdfs], axis=0)\n",
    "list_head.append(\"Class\")\n",
    "final_df = pd.DataFrame(final_df, columns=list_head, index=None)\n",
    "final_df.to_csv(OUTPATH+os.sep+\"32FINAL.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
